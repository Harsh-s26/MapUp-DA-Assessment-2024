{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffbecc5",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "1)Write a function that takes a list and an integer n, and returns the list with every group of n elements reversed. If there are fewer than n elements left at the end, reverse all of them.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "You must not use any built-in slicing or reverse functions to directly reverse the sublists.\n",
    "The result should reverse the elements in groups of size n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6392977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 60, 70, 10, 20, 30, 40]\n"
     ]
    }
   ],
   "source": [
    "def rotate_list(lst,position):\n",
    "    position = position%len(lst)\n",
    "    rtd_list = lst[position:]+lst[:position]\n",
    "    return rtd_list\n",
    "lst=[10,20,30,40,50,60,70]\n",
    "position = 4\n",
    "print(rotate_list(lst,position))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b15208",
   "metadata": {},
   "source": [
    "2)Problem Statement:\n",
    "\n",
    "Write a function that takes a list of strings and groups them by their length. The result should be a dictionary where:\n",
    "\n",
    "The keys are the string lengths.\n",
    "The values are lists of strings that have the same length as the key.\n",
    "Requirements:\n",
    "\n",
    "Each string should appear in the list corresponding to its length.\n",
    "The result should be sorted by the lengths (keys) in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f035669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['one', 'two'], 4: ['four'], 5: ['three']}\n"
     ]
    }
   ],
   "source": [
    "def group_strings_by_length(strings):\n",
    "    grouped_strings = {}\n",
    "    for string in strings:\n",
    "        length = len(string)\n",
    "        if length not in grouped_strings:\n",
    "              grouped_strings[length] = []\n",
    "        grouped_strings[length].append(string)\n",
    "\n",
    "    return dict(sorted(grouped_strings.items()))\n",
    "strings = [\"one\",\"two\",'three','four']\n",
    "result = group_strings_by_length(strings)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccfd56",
   "metadata": {},
   "source": [
    "3) You are given a nested dictionary that contains various details (including lists and sub-dictionaries). Your task is to write a Python function that flattens the dictionary such that:\n",
    "\n",
    "Nested keys are concatenated into a single key with levels separated by a dot (.).\n",
    "List elements should be referenced by their index, enclosed in square brackets (e.g., sections[0]).\n",
    "For example, if a key points to a list, the index of the list element should be appended to the key string, followed by a dot to handle further nested dictionaries.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Nested Dictionary: Flatten nested dictionaries into a single level, concatenating keys.\n",
    "Handling Lists: Flatten lists by using the index as part of the key.\n",
    "Key Separator: Use a dot (.) as a separator between nested key levels.\n",
    "Empty Input: The function should handle empty dictionaries gracefully.\n",
    "Nested Depth: You can assume the dictionary has a maximum of 4 levels of nesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697b279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'road.name': 'Highway 1', 'road.length': 350, 'road.sections[0].id': 1, 'road.sections[0].condition.pavement': 'good', 'road.sections[0].condition.traffic': 'moderate'}\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(d, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        \n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for idx, item in enumerate(v):\n",
    "                list_key = f\"{new_key}[{idx}]\"\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_dict(item, list_key, sep=sep).items())\n",
    "                else:\n",
    "                    items.append((list_key, item))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    \n",
    "    return dict(items)\n",
    "\n",
    "nested_dict = {\n",
    "    \"road\": {\n",
    "        \"name\": \"Highway 1\",\n",
    "        \"length\": 350,\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"condition\": {\n",
    "                    \"pavement\": \"good\",\n",
    "                    \"traffic\": \"moderate\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "flattened_dict = flatten_dict(nested_dict)\n",
    "print(flattened_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4838b",
   "metadata": {},
   "source": [
    "4)Problem Statement:\n",
    "\n",
    "You are given a list of integers that may contain duplicates. Your task is to generate all unique permutations of the list. The output should not contain any duplicate permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0d40ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "def permute(nums):\n",
    "    result = []\n",
    "    used = [False] * len(nums)\n",
    "    def backtrack(start, path):\n",
    "        if len(path) == len(nums):\n",
    "            result.append(path[:])\n",
    "            return\n",
    "        for i in range(start, len(nums)):\n",
    "            if not used[i] and (i == start or nums[i] != nums[i - 1] or used[i - 1]):\n",
    "                used[i] = True\n",
    "                path.append(nums[i])\n",
    "                backtrack(start + 1, path)\n",
    "                path.pop()\n",
    "                used[i] = False\n",
    "\n",
    "    nums.sort() \n",
    "    backtrack(0, [])\n",
    "    return result\n",
    "nums = [1, 1, 2]\n",
    "permutations = permute(nums)\n",
    "print(permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1af29d",
   "metadata": {},
   "source": [
    "5)Problem Statement:\n",
    "\n",
    "You are given a string that contains dates in various formats (such as \"dd-mm-yyyy\", \"mm/dd/yyyy\", \"yyyy.mm.dd\", etc.). Your task is to identify and return all the valid dates present in the string.\n",
    "\n",
    "You need to write a function find_all_dates that takes a string as input and returns a list of valid dates found in the text. The dates can be in any of the following formats:\n",
    "\n",
    "dd-mm-yyyy\n",
    "mm/dd/yyyy\n",
    "yyyy.mm.dd\n",
    "You are required to use regular expressions to identify these dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7114444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23-08', '08-23', '08-2']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_all_dates(text):\n",
    "    all_dates = []\n",
    "    date_formats = [\n",
    "        r\"\\b(0?[1-9]|[12][0-9]|3[01])-(0?[1-9]|1[0-2])-\\d{4}\",   \n",
    "        r\"\\b(0?[1-9]|1[0-2])/(0?[1-9]|[12][0-9]|3[01])/\\d{4}\",   \n",
    "        r\"\\b\\d{4}\\.(0?[1-9]|1[0-2])\\.(0?[1-9]|[12][0-9]|3[01])\" \n",
    "    ]\n",
    "    \n",
    "    for date_format in date_formats:\n",
    "        matches = re.findall(date_format, text)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                all_dates.append(\"-\".join(match))  # Join the tuple to make the full date\n",
    "            else:\n",
    "                all_dates.append(match)\n",
    "    \n",
    "    return all_dates\n",
    "\n",
    "text = \"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\"\n",
    "valid_dates = find_all_dates(text)\n",
    "print(valid_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a43463",
   "metadata": {},
   "source": [
    "6)You are given a polyline string, which encodes a series of latitude and longitude coordinates. Polyline encoding is a method to efficiently store latitude and longitude data using fewer bytes. The Python polyline module allows you to decode this string into a list of coordinates.\n",
    "\n",
    "Write a function that performs the following operations:\n",
    "\n",
    "Decode the polyline string using the polyline module into a list of (latitude, longitude) coordinates.\n",
    "Convert these coordinates into a Pandas DataFrame with the following columns:\n",
    "latitude: Latitude of the coordinate.\n",
    "longitude: Longitude of the coordinate.\n",
    "distance: The distance (in meters) between the current row's coordinate and the previous row's one. The first row will have a distance of 0 since there is no previous point.\n",
    "Calculate the distance using the Haversine formula for points in successive rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf13d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyline\n",
      "  Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: polyline\n",
      "Successfully installed polyline-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install polyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7716eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude   distance\n",
      "0  40.63179   -8.65708   0.000000\n",
      "1  40.63143   -8.65812  96.460878\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polyline\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def decode_polyline_to_df(polyline_str):\n",
    "    coords = polyline.decode(polyline_str)\n",
    "    df = pd.DataFrame(coords, columns=['latitude', 'longitude'])\n",
    "    df['distance'] = 0.0\n",
    "    for i in range(1, len(df)):\n",
    "        lat1, lon1 = df.loc[i - 1, 'latitude'], df.loc[i - 1, 'longitude']\n",
    "        lat2, lon2 = df.loc[i, 'latitude'], df.loc[i, 'longitude']\n",
    "        df.loc[i, 'distance'] = haversine(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    return df\n",
    "\n",
    "polyline_str = 'u{~vFvyys@fAnE'\n",
    "df = decode_polyline_to_df(polyline_str)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632a610",
   "metadata": {},
   "source": [
    "7)Write a function that performs the following operations on a square matrix (n x n):\n",
    "\n",
    "Rotate the matrix by 90 degrees clockwise.\n",
    "After rotation, for each element in the rotated matrix, replace it with the sum of all elements in the same row and column (in the rotated matrix), excluding itself.\n",
    "The function should return the transformed matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17e24c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 23, 17], [31, 25, 19], [33, 27, 21]]\n"
     ]
    }
   ],
   "source": [
    "def rotate_and_transform_matrix(matrix):\n",
    "    n = len(matrix)\n",
    "    rotated_matrix = [[0] * n for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            rotated_matrix[j][n - 1 - i] = matrix[i][j]\n",
    "    final_matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            row_sum = sum(rotated_matrix[i])  \n",
    "            col_sum = sum(rotated_matrix[k][j] for k in range(n))  \n",
    "            final_matrix[i][j] = row_sum + col_sum - rotated_matrix[i][j] \n",
    "\n",
    "    return final_matrix\n",
    "matrix = [[1, 2, 3],[4, 5, 6],[7, 8, 9]]\n",
    "result = rotate_and_transform_matrix(matrix)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616799d1",
   "metadata": {},
   "source": [
    "8)Time Check\n",
    "You are given a dataset, dataset-1.csv, containing columns id, id_2, and timestamp (startDay, startTime, endDay, endTime). The goal is to verify the completeness of the time data by checking whether the timestamps for each unique (id, id_2) pair cover a full 24-hour period (from 12:00:00 AM to 11:59:59 PM) and span all 7 days of the week (from Monday to Sunday).\n",
    "\n",
    "Create a function that accepts dataset-1.csv as a DataFrame and returns a boolean series that indicates if each (id, id_2) pair has incorrect timestamps. The boolean series must have multi-index (id, id_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ef70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_time_data_completeness(df):\n",
    "    df['start_timestamp'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'])\n",
    "    df['end_timestamp'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'])\n",
    "    df.set_index(['id', 'id_2'], inplace=True)\n",
    "    def check_completeness(group):\n",
    "        days_covered = group['start_timestamp'].dt.dayofweek.unique()\n",
    "        all_days_covered = set(range(7))  \n",
    "        time_coverage = (group['start_timestamp'].min().time() <= pd.Timestamp('00:00:00').time() and \n",
    "                         group['end_timestamp'].max().time() >= pd.Timestamp('23:59:59').time())\n",
    "        return len(days_covered) == 7 and time_coverage\n",
    "    completeness = df.groupby(level=[0, 1]).apply(check_completeness)\n",
    "\n",
    "    return completeness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275aa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff8227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31315e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04c717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e01a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439700f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc482fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91d0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747da08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb132f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c749616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23242afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73421955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99643b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a262123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3d059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab7034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74971e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba517e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2de08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c1d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a6a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a6d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7d1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627888b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f756e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5bd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029805f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
